{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cuda.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMZm0YTUOnR3",
        "colab_type": "text"
      },
      "source": [
        "# Projekat 2\n",
        "- Rok za predaju je termin odbrane u toku 2. kolokvijumske nedelje\n",
        "- Projekat je moguće raditi u paru ili samostalno\n",
        "- Svaka stavka nosi po 10 bodova\n",
        "\n",
        "Koristeći PyCuda okurženje napisati CUDA program za (matrično) množenje matrica.\n",
        "\n",
        "1. Program koji vrši množenja matrica malih dimenzija (množenje se može izvršiti upotrebom jednom bloka niti)\n",
        "2. Probram koji vrši množenje matrica većih dimenzija, upotrebom većeg broja CUDA blokova.\n",
        "3. Ubrzati rešenje iz stavke 2 upotrebom deljene memorije (tako da niti jednog bloka prvo dovuku deo podataka u deljenu memeorju, a potom sve čitaju iz deljene memorije)\n",
        "4. Izmeniti rešenje iz tačke 3 tako da se pri množenju druga matrica transponuje ($Rezultat = A \\cdot B^T$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZQuEf7PQH8R",
        "colab_type": "code",
        "outputId": "79bcd63f-b3ab-48a1-a7ed-180dd4ebb1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/3f/5658c38579b41866ba21ee1b5020b8225cec86fe717e4b1c5c972de0a33c/pycuda-2019.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 57.6MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/c7/88a4f8b6f0f78d0115ec3320861a0cc1f6daa3b67e97c3c2842c33f9c089/pytools-2020.1.tar.gz (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.1)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/03/329b21f00243fc2d3815399413845dbbfb0745cff38a29d3597e97f8be58/Mako-1.1.1.tar.gz (468kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 62.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.17.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools, mako\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2019.1.2-cp36-cp36m-linux_x86_64.whl size=4535180 sha256=c1d2e7a96f26d6b9c6c246b4a55953154fa317665261a11135f390758b2b9e87\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/60/f0/b1c430c73d281ac3e46070480db50f7907364eb6f6d3188396\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.1-py2.py3-none-any.whl size=59602 sha256=c46fe4335cf027257521444a25d39cb8c1343888b66852c3bd5a28b5abb09c7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/da/1b/946775a88291378182ed92c9800d6d0ebc2a554cb89829cc24\n",
            "  Building wheel for mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mako: filename=Mako-1.1.1-cp36-none-any.whl size=75410 sha256=e159a6dc0ca64072c597095dd72449162aba2c7cad573e6c11d3b28ce29b6a91\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/50/a9/0ddeed8679a1fb65bf4677cb9c92701828b2c1821e22ef72fd\n",
            "Successfully built pycuda pytools mako\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.3 mako-1.1.1 pycuda-2019.1.2 pytools-2020.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Uf0i5ijDQ7",
        "colab_type": "code",
        "outputId": "d0944434-ba64-414d-ef34-55c8baa56870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Dec 19 16:52:04 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-mBbf6flkqN",
        "colab_type": "text"
      },
      "source": [
        "1. Program koji vrši množenja matrica malih dimenzija (množenje se može izvršiti upotrebom jednom bloka niti)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp1RxjsGkIzx",
        "colab_type": "code",
        "outputId": "5a459843-d001-4636-f901-9a973be28a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "        __global__ void multiplyMatrixOneBlock(float *a,float *b, float *c, int colsA,int colsB){\n",
        "              int idxC = threadIdx.x+threadIdx.y*colsB;\n",
        "              int idxA = threadIdx.y*colsA;\n",
        "              int idxB = threadIdx.x;\n",
        "\n",
        "              int i=0;\n",
        "\n",
        "              for(i;i<colsA;i++){\n",
        "                c[idxC] += a[idxA+i]*b[idxB];\n",
        "                idxB += colsB;\n",
        "              }\n",
        "            }\n",
        "        \"\"\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "kernel.cu(10): warning: expression has no effect\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNGBOM17q-m",
        "colab_type": "code",
        "outputId": "1b71b379-3e96-4b15-aa10-c7473c4e6809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.random.randn(20,10).astype(dtype=np.float32)\n",
        "b = np.random.randn(10,10).astype(dtype=np.float32)\n",
        "# print(b)\n",
        "res = a.dot(b)\n",
        "\n",
        "c = np.zeros_like(res)\n",
        "# print(c)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "func = mod.get_function(\"multiplyMatrixOneBlock\")\n",
        "func(a_gpu,b_gpu,c_gpu,np.int32(a.shape[1]),np.int32(b.shape[1]),block=(np.int(b.shape[1]),np.int(a.shape[0]),1),grid=(1,1,1))\n",
        "\n",
        "cuda.memcpy_dtoh(c,c_gpu)\n",
        "\n",
        "print(res)\n",
        "print(\"\\n\")\n",
        "print(c)\n",
        "\n",
        "print(\"Dobijen ocekivan rezultat: \",(c==res).all())\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-6.61319261e-03 -1.03212273e+00 -6.60954905e+00 -2.94812679e+00\n",
            "   3.08738732e+00 -6.59219146e-01 -1.69506133e+00  1.19594723e-01\n",
            "  -2.52241397e+00 -2.90766716e+00]\n",
            " [ 3.11278701e+00 -5.93282747e+00 -3.01727200e+00  8.34733307e-01\n",
            "  -8.91571331e+00  1.76132631e+00  5.49504900e+00 -1.51824605e+00\n",
            "   2.08662438e+00  2.05112982e+00]\n",
            " [ 3.40328884e+00  1.59361362e+00 -6.54365396e+00 -6.70715761e+00\n",
            "  -6.87209272e+00  2.76411700e+00  6.42351675e+00  2.31044388e+00\n",
            "  -3.65087605e+00 -5.73620200e-01]\n",
            " [ 1.22270966e+00  3.05270743e+00 -7.36995935e-01 -4.12804365e+00\n",
            "  -4.18360758e+00  2.33640695e+00  3.93337345e+00  7.53668189e-01\n",
            "  -8.81967366e-01 -3.06086540e-01]\n",
            " [-2.44525552e-01  1.42606705e-01  5.84352136e-01  2.60837126e+00\n",
            "   5.04781246e-01  1.44806087e+00  1.81941319e+00  4.85533619e+00\n",
            "   2.20984578e+00 -1.15936124e+00]\n",
            " [-5.93612480e+00 -5.62515450e+00 -3.00647712e+00  2.00549340e+00\n",
            "  -5.43911457e-01 -9.67341602e-01 -8.01352143e-01 -1.62194312e-01\n",
            "   2.78397727e+00  8.48718047e-01]\n",
            " [ 4.52064705e+00  4.83218145e+00 -1.56495261e+00 -3.71173906e+00\n",
            "   5.51003361e+00  7.21972644e-01 -3.68351412e+00 -5.92312384e+00\n",
            "  -4.30554104e+00 -1.78704783e-02]\n",
            " [ 6.67756653e+00 -1.79091752e+00 -5.13491535e+00 -2.45664644e+00\n",
            "   1.30685341e+00 -8.50212455e-01 -4.72894812e+00 -5.98341465e+00\n",
            "  -2.95845270e+00 -4.55993319e+00]\n",
            " [ 5.79826534e-01  1.45772159e-01 -6.01211905e-01 -3.27550626e+00\n",
            "  -6.88062954e+00  1.40075564e+00  7.51246881e+00  3.09897995e+00\n",
            "   2.80317330e+00  2.05189204e+00]\n",
            " [-3.49493074e+00 -4.08848000e+00 -1.03969848e+00  2.37503481e+00\n",
            "   1.09872532e+00  5.48706055e-01  2.62118769e+00  9.81595874e-01\n",
            "   4.36107731e+00  3.10742640e+00]\n",
            " [ 6.03784978e-01 -3.47841763e+00 -2.39037722e-02  4.32083273e+00\n",
            "  -2.36447406e+00 -2.09244084e+00 -5.35062790e-01  1.83569133e-01\n",
            "   5.84141850e-01 -1.25066233e+00]\n",
            " [ 1.81237638e-01  7.46798754e+00  4.20706224e+00 -5.73999977e+00\n",
            "  -3.03580500e-02  1.97571754e+00  2.22155690e+00  2.29349160e+00\n",
            "  -2.44721055e+00  2.14355278e+00]\n",
            " [ 7.89932311e-01  2.12979293e+00  2.51564360e+00  5.93032479e-01\n",
            "  -5.05952787e+00 -3.02158809e+00 -3.80743408e+00  1.11719000e+00\n",
            "  -4.50276709e+00 -5.81446266e+00]\n",
            " [ 1.03772366e+00  3.95679504e-01  5.79510748e-01 -1.07473338e+00\n",
            "   1.34944952e+00 -2.59015894e+00 -3.80464292e+00 -3.11216861e-01\n",
            "   4.12978321e-01 -3.74631596e+00]\n",
            " [-1.52336979e+00 -1.05944872e-01  4.32501364e+00  1.39520991e+00\n",
            "   1.35365546e+00 -2.17683434e+00 -2.55683017e+00  1.80608988e+00\n",
            "   3.60622931e+00 -2.36052370e+00]\n",
            " [-2.38632345e+00 -7.81653309e+00 -2.89265275e+00  3.94154119e+00\n",
            "   2.55050445e+00 -2.64944792e+00  5.58698833e-01  5.22795320e-01\n",
            "   7.52978849e+00  5.24962604e-01]\n",
            " [-9.82099175e-01  1.97272551e+00 -1.46865761e+00 -1.43172705e+00\n",
            "   2.16317272e+00  9.04293001e-01 -8.18656564e-01 -6.56772196e-01\n",
            "  -3.76164913e+00  1.04764497e+00]\n",
            " [ 5.70955467e+00 -1.19408794e-01 -2.90667009e+00 -2.12464762e+00\n",
            "  -3.85510492e+00 -1.16786659e+00  6.62835360e-01  2.64945579e+00\n",
            "  -4.02946711e+00 -5.01740170e+00]\n",
            " [-2.49402836e-01  4.84928179e+00  4.48063993e+00 -2.77152109e+00\n",
            "   2.05029821e+00  3.63997006e+00  1.36424899e+00  3.19397271e-01\n",
            "   1.70981681e+00  3.89079785e+00]\n",
            " [ 1.80190384e+00 -2.79049063e+00 -1.80117130e-01 -5.86497426e-01\n",
            "  -5.37700319e+00 -2.37325954e+00  2.07504654e+00  1.38308656e+00\n",
            "   2.02768040e+00 -1.55920208e+00]]\n",
            "\n",
            "\n",
            "[[-6.61319261e-03 -1.03212273e+00 -6.60954905e+00 -2.94812679e+00\n",
            "   3.08738732e+00 -6.59219146e-01 -1.69506133e+00  1.19594723e-01\n",
            "  -2.52241397e+00 -2.90766716e+00]\n",
            " [ 3.11278701e+00 -5.93282747e+00 -3.01727200e+00  8.34733307e-01\n",
            "  -8.91571331e+00  1.76132631e+00  5.49504900e+00 -1.51824605e+00\n",
            "   2.08662438e+00  2.05112982e+00]\n",
            " [ 3.40328884e+00  1.59361362e+00 -6.54365396e+00 -6.70715761e+00\n",
            "  -6.87209272e+00  2.76411700e+00  6.42351675e+00  2.31044388e+00\n",
            "  -3.65087605e+00 -5.73620200e-01]\n",
            " [ 1.22270966e+00  3.05270743e+00 -7.36995935e-01 -4.12804365e+00\n",
            "  -4.18360758e+00  2.33640695e+00  3.93337345e+00  7.53668189e-01\n",
            "  -8.81967366e-01 -3.06086540e-01]\n",
            " [-2.44525552e-01  1.42606705e-01  5.84352136e-01  2.60837126e+00\n",
            "   5.04781246e-01  1.44806087e+00  1.81941319e+00  4.85533619e+00\n",
            "   2.20984578e+00 -1.15936124e+00]\n",
            " [-5.93612480e+00 -5.62515450e+00 -3.00647712e+00  2.00549340e+00\n",
            "  -5.43911457e-01 -9.67341602e-01 -8.01352143e-01 -1.62194312e-01\n",
            "   2.78397727e+00  8.48718047e-01]\n",
            " [ 4.52064705e+00  4.83218145e+00 -1.56495261e+00 -3.71173906e+00\n",
            "   5.51003361e+00  7.21972644e-01 -3.68351412e+00 -5.92312384e+00\n",
            "  -4.30554104e+00 -1.78704783e-02]\n",
            " [ 6.67756653e+00 -1.79091752e+00 -5.13491535e+00 -2.45664644e+00\n",
            "   1.30685341e+00 -8.50212455e-01 -4.72894812e+00 -5.98341465e+00\n",
            "  -2.95845270e+00 -4.55993319e+00]\n",
            " [ 5.79826534e-01  1.45772159e-01 -6.01211905e-01 -3.27550626e+00\n",
            "  -6.88062954e+00  1.40075564e+00  7.51246881e+00  3.09897995e+00\n",
            "   2.80317330e+00  2.05189204e+00]\n",
            " [-3.49493074e+00 -4.08848000e+00 -1.03969848e+00  2.37503481e+00\n",
            "   1.09872532e+00  5.48706055e-01  2.62118769e+00  9.81595874e-01\n",
            "   4.36107731e+00  3.10742640e+00]\n",
            " [ 6.03784978e-01 -3.47841763e+00 -2.39037722e-02  4.32083273e+00\n",
            "  -2.36447406e+00 -2.09244084e+00 -5.35062790e-01  1.83569133e-01\n",
            "   5.84141850e-01 -1.25066233e+00]\n",
            " [ 1.81237638e-01  7.46798754e+00  4.20706224e+00 -5.73999977e+00\n",
            "  -3.03580500e-02  1.97571754e+00  2.22155690e+00  2.29349160e+00\n",
            "  -2.44721055e+00  2.14355278e+00]\n",
            " [ 7.89932311e-01  2.12979293e+00  2.51564360e+00  5.93032479e-01\n",
            "  -5.05952787e+00 -3.02158809e+00 -3.80743408e+00  1.11719000e+00\n",
            "  -4.50276709e+00 -5.81446266e+00]\n",
            " [ 1.03772366e+00  3.95679504e-01  5.79510748e-01 -1.07473338e+00\n",
            "   1.34944952e+00 -2.59015894e+00 -3.80464292e+00 -3.11216861e-01\n",
            "   4.12978321e-01 -3.74631596e+00]\n",
            " [-1.52336979e+00 -1.05944872e-01  4.32501364e+00  1.39520991e+00\n",
            "   1.35365546e+00 -2.17683434e+00 -2.55683017e+00  1.80608988e+00\n",
            "   3.60622931e+00 -2.36052370e+00]\n",
            " [-2.38632345e+00 -7.81653309e+00 -2.89265275e+00  3.94154119e+00\n",
            "   2.55050445e+00 -2.64944792e+00  5.58698833e-01  5.22795320e-01\n",
            "   7.52978849e+00  5.24962604e-01]\n",
            " [-9.82099175e-01  1.97272551e+00 -1.46865761e+00 -1.43172705e+00\n",
            "   2.16317272e+00  9.04293001e-01 -8.18656564e-01 -6.56772196e-01\n",
            "  -3.76164913e+00  1.04764497e+00]\n",
            " [ 5.70955467e+00 -1.19408794e-01 -2.90667009e+00 -2.12464762e+00\n",
            "  -3.85510492e+00 -1.16786659e+00  6.62835360e-01  2.64945579e+00\n",
            "  -4.02946711e+00 -5.01740170e+00]\n",
            " [-2.49402836e-01  4.84928179e+00  4.48063993e+00 -2.77152109e+00\n",
            "   2.05029821e+00  3.63997006e+00  1.36424899e+00  3.19397271e-01\n",
            "   1.70981681e+00  3.89079785e+00]\n",
            " [ 1.80190384e+00 -2.79049063e+00 -1.80117130e-01 -5.86497426e-01\n",
            "  -5.37700319e+00 -2.37325954e+00  2.07504654e+00  1.38308656e+00\n",
            "   2.02768040e+00 -1.55920208e+00]]\n",
            "Dobijen ocekivan rezultat:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nq9_fyil2PJ",
        "colab_type": "text"
      },
      "source": [
        "2. Program koji vrši množenje matrica većih dimenzija, upotrebom većeg broja CUDA blokova."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6YWtV4FS565",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "        __global__ void multiplyMatrixMultipleBlocksaaa(float *a,float *b, float *c,int colsB,int rowsA,int colsA){\n",
        "              long idxC = threadIdx.x + blockDim.x*blockIdx.x + threadIdx.y*colsB + blockDim.y*blockIdx.y*colsB;\n",
        "              long idxA = (threadIdx.y + blockDim.y*blockIdx.y)*colsA;\n",
        "              long idxB = blockDim.x*blockIdx.x+threadIdx.x;\n",
        "\n",
        "              if(idxB > colsB) return;\n",
        "              if(threadIdx.y + blockDim.y*blockIdx.y > rowsA) return;\n",
        "             \n",
        "\n",
        "              for(int i = 0;i<colsA;i++){\n",
        "                c[idxC] += a[idxA+i]*b[idxB];\n",
        "                idxB += colsB;\n",
        "              }\n",
        "            }\n",
        "        \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d9ef71a1-c2e0-45d1-e69b-81b962dd8815",
        "id": "y5TI3myvYY80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "a = np.random.randn(90,64).astype(dtype=np.float32)\n",
        "b = np.random.randn(64,50).astype(dtype=np.float32)\n",
        "\n",
        "res = a.dot(b)\n",
        "\n",
        "c = np.zeros_like(res)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "func = mod.get_function(\"multiplyMatrixMultipleBlocksaaa\")\n",
        "func(a_gpu, b_gpu, c_gpu,np.int32(b.shape[1]),np.int32(a.shape[0]),np.int32(a.shape[1]),block=(32, 32, 1), grid=(math.ceil(b.shape[1]/32), math.ceil(a.shape[0]/32), 1))\n",
        "\n",
        "cuda.memcpy_dtoh(c,c_gpu)\n",
        "print(res)\n",
        "print(\"\\n\")\n",
        "print(c)\n",
        "print(\"Dobijen ocekivan rezultat: \",(c==res).all())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  8.059529    -2.9514744   19.793642   ...   0.77876675  -1.9025819\n",
            "    4.662512  ]\n",
            " [  5.1823907   -8.657698     5.429327   ...  -3.2701514    2.2115963\n",
            "  -20.331495  ]\n",
            " [  7.914715    13.15319     -6.9358788  ... -14.764278     5.5255246\n",
            "   -8.185326  ]\n",
            " ...\n",
            " [ -0.3132923   18.790424     5.3004994  ...   1.3879613   -4.4121203\n",
            "    5.031723  ]\n",
            " [ -4.4500666    7.9562087  -11.3538885  ...  11.753639   -12.153389\n",
            "    1.573964  ]\n",
            " [-12.711066     2.6455061    6.8246527  ...  12.291165   -13.488839\n",
            "    1.153004  ]]\n",
            "\n",
            "\n",
            "[[  8.059529    -2.9514744   19.793642   ...   0.77876675  -1.9025819\n",
            "    4.662512  ]\n",
            " [  5.1823907   -8.657698     5.429327   ...  -3.2701514    2.2115963\n",
            "  -20.331495  ]\n",
            " [  7.914715    13.15319     -6.9358788  ... -14.764278     5.5255246\n",
            "   -8.185326  ]\n",
            " ...\n",
            " [ -0.3132923   18.790424     5.3004994  ...   1.3879613   -4.4121203\n",
            "    5.031723  ]\n",
            " [ -4.4500666    7.9562087  -11.3538885  ...  11.753639   -12.153389\n",
            "    1.573964  ]\n",
            " [-12.711066     2.6455061    6.8246527  ...  12.291165   -13.488839\n",
            "    1.153004  ]]\n",
            "Dobijen ocekivan rezultat:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSWua59fa4cR",
        "colab_type": "text"
      },
      "source": [
        "3. Ubrzati rešenje iz stavke 2 upotrebom deljene memorije (tako da niti jednog bloka prvo dovuku deo podataka u deljenu memeorju, a potom sve čitaju iz deljene memorije)    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyDV6xTNbDqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "        __global__ void multiplyMatrixMultipleBlocksSharedMemory(float *a,float *b, float *c,int rowsA, int colsA,\n",
        "                                                                  int rowsB,int colsB,int rowsC,int colsC){\n",
        "              float cValue = 0;\n",
        "\n",
        "              int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "              int col = blockIdx.x * blockDim.y + threadIdx.x;\n",
        "\n",
        "              __shared__ float aVal[32][32];\n",
        "              __shared__ float bVal[32][32];\n",
        "\n",
        "              for(int i = 0; i < (blockDim.y + colsA - 1)/blockDim.y;i++){\n",
        "                if(i*blockDim.y + threadIdx.x < colsA && row < rowsA){\n",
        "                  aVal[threadIdx.y][threadIdx.x] = a[row*colsA + i*blockDim.y + threadIdx.x];\n",
        "                } else {\n",
        "                  aVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                if(i * blockDim.y + threadIdx.y < rowsB && col < colsB){\n",
        "                  bVal[threadIdx.y][threadIdx.x] = b[(i*blockDim.y + threadIdx.y)* colsB + col];\n",
        "                } else {\n",
        "                  bVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                for(int j = 0 ; j < blockDim.y ; ++j){\n",
        "                  cValue += aVal[threadIdx.y][j] * bVal[j][threadIdx.x];\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                if(row < rowsC && col < colsC){\n",
        "                  c[((blockIdx.y * blockDim.y) + threadIdx.y) * colsC + (blockIdx.x * blockDim.x) + threadIdx.x] = cValue;\n",
        "                }                \n",
        "              } \n",
        "            }\n",
        "        \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NSj8zEKbKQ7",
        "colab_type": "code",
        "outputId": "967e517b-5e95-47a5-ebf1-199ae88e3677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "a = np.random.randn(40,64).astype(dtype=np.float32)\n",
        "b = np.random.randn(64,90).astype(dtype=np.float32)\n",
        "\n",
        "res = a.dot(b)\n",
        "\n",
        "c = np.zeros_like(res)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "func = mod.get_function(\"multiplyMatrixMultipleBlocksSharedMemory\")\n",
        "func(a_gpu, b_gpu, c_gpu,np.int32(a.shape[0]),np.int32(a.shape[1]),np.int32(b.shape[0]),np.int32(b.shape[1]),\n",
        "     np.int32(a.shape[0]),np.int32(b.shape[1]),block=(32, 32, 1), grid=(math.ceil(b.shape[1]/32), math.ceil(a.shape[0]/32), 1))\n",
        "\n",
        "cuda.memcpy_dtoh(c,c_gpu)\n",
        "print(res)\n",
        "print(\"\\n\")\n",
        "print(c)\n",
        "print(\"Dobijen ocekivan rezultat: \",(c==res).all())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  5.765109    12.437745    12.543252   ...  -0.48804048 -18.68554\n",
            "   -2.8234823 ]\n",
            " [ -1.1579032   16.959457    -0.67889977 ... -14.982883    10.15992\n",
            "   -6.843334  ]\n",
            " [-11.283044     6.9160376   10.162625   ...  12.919693    -0.49158838\n",
            "    4.5014462 ]\n",
            " ...\n",
            " [-14.676378    12.977117    13.151093   ...  16.911741     3.1119206\n",
            "   -3.4816144 ]\n",
            " [ -7.7833877    3.412491    -7.264991   ...  -7.1473784   -2.6236696\n",
            "   -6.525996  ]\n",
            " [  6.107656     1.0148576   -1.7636495  ...   2.045672    -9.665419\n",
            "    2.4342937 ]]\n",
            "\n",
            "\n",
            "[[  5.765109    12.437745    12.543252   ...  -0.48804048 -18.68554\n",
            "   -2.8234823 ]\n",
            " [ -1.1579032   16.959457    -0.67889977 ... -14.982883    10.15992\n",
            "   -6.843334  ]\n",
            " [-11.283044     6.9160376   10.162625   ...  12.919693    -0.49158838\n",
            "    4.5014462 ]\n",
            " ...\n",
            " [-14.676378    12.977117    13.151093   ...  16.911741     3.1119206\n",
            "   -3.4816144 ]\n",
            " [ -7.7833877    3.412491    -7.264991   ...  -7.1473784   -2.6236696\n",
            "   -6.525996  ]\n",
            " [  6.107656     1.0148576   -1.7636495  ...   2.045672    -9.665419\n",
            "    2.4342937 ]]\n",
            "Dobijen ocekivan rezultat:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heZUmNQDZ3YI",
        "colab_type": "text"
      },
      "source": [
        "4. Izmeniti rešenje iz tačke 3 tako da se pri množenju druga matrica transponuje ($Rezultat = A \\cdot B^T$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd2lGqe0Z66k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "\n",
        "        __global__ void multiplyMatrixMultipleBlocksSharedMemory(float *a,float *b, float *c,int rowsA, int colsA,\n",
        "                                                                  int rowsB,int colsB,int rowsC,int colsC){\n",
        "              float cValue = 0;\n",
        "\n",
        "              int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "              int col = blockIdx.x * blockDim.y + threadIdx.x;\n",
        "\n",
        "              __shared__ float aVal[32][32];\n",
        "              __shared__ float bVal[32][32];\n",
        "\n",
        "              for(int i = 0; i < (colsA - 1)/blockDim.x + 1;i++){\n",
        "                if(i*blockDim.y + threadIdx.x < colsA && row < rowsA){\n",
        "                  aVal[threadIdx.y][threadIdx.x] = a[row*colsA + i*blockDim.x + threadIdx.x];\n",
        "                } else {\n",
        "                  aVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                if(i * blockDim.x + threadIdx.y < colsB && col < rowsB){\n",
        "                  bVal[threadIdx.y][threadIdx.x] = b[(i*blockDim.y + threadIdx.y)+ colsB * col];\n",
        "                } else {\n",
        "                  bVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                for(int j = 0 ; j < blockDim.y ; ++j){\n",
        "                  cValue += aVal[threadIdx.y][j] * bVal[j][threadIdx.x];\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                if(row < rowsC && col < colsC){\n",
        "                  c[row*colsC+col] = cValue;\n",
        "                }                 \n",
        "              } \n",
        "            }\n",
        "        \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_nmdtB-3RdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "8a22c9c9-e210-445c-e522-987ad50c89ad"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "a = np.random.randn(40,64).astype(dtype=np.float32)\n",
        "b = np.random.randn(90,64).astype(dtype=np.float32)\n",
        "\n",
        "a_rows = np.int32(a.shape[0])\n",
        "a_cols = np.int32(a.shape[1])\n",
        "\n",
        "b_rows = np.int32(b.shape[0])\n",
        "b_cols = np.int32(b.shape[1])\n",
        "\n",
        "res = a.dot(np.transpose(b))\n",
        "\n",
        "c = np.zeros_like(res)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "func = mod.get_function(\"multiplyMatrixMultipleBlocksSharedMemory\")\n",
        "func(a_gpu, b_gpu, c_gpu,a_rows,a_cols,b_rows,b_cols,\n",
        "     a_rows,b_rows,block=(32, 32, 1), grid=(math.ceil(b_rows/32), math.ceil(a_rows/32), 1))\n",
        "\n",
        "cuda.memcpy_dtoh(c,c_gpu)\n",
        "print(res)\n",
        "print(\"\\n\")\n",
        "print(c)\n",
        "print(\"Dobijen ocekivan rezultat: \",(c==res).all())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  4.433159   -12.212397     9.166139   ...  -6.384378    14.973863\n",
            "   -6.887016  ]\n",
            " [ -1.743611    -3.532164    14.190903   ...   7.9171133   -6.845802\n",
            "    7.449575  ]\n",
            " [  2.9409366   -2.977142    -4.4708385  ...  -6.2097006   -3.0482185\n",
            "   15.085486  ]\n",
            " ...\n",
            " [  8.189446    -1.9610255    1.7757114  ... -13.651409    -0.24192235\n",
            "    4.1073117 ]\n",
            " [ -1.8791156    7.0345764    0.6736483  ... -11.351215    -5.9611197\n",
            "    4.4481745 ]\n",
            " [  4.0102777   -9.1871       7.4591684  ...  -4.826018     2.7697608\n",
            "    4.7740536 ]]\n",
            "\n",
            "\n",
            "[[  4.433159   -12.212397     9.166139   ...  -6.384378    14.973863\n",
            "   -6.887016  ]\n",
            " [ -1.743611    -3.532164    14.190903   ...   7.9171133   -6.845802\n",
            "    7.449575  ]\n",
            " [  2.9409366   -2.977142    -4.4708385  ...  -6.2097006   -3.0482185\n",
            "   15.085486  ]\n",
            " ...\n",
            " [  8.189446    -1.9610255    1.7757114  ... -13.651409    -0.24192235\n",
            "    4.1073117 ]\n",
            " [ -1.8791156    7.0345764    0.6736483  ... -11.351215    -5.9611197\n",
            "    4.4481745 ]\n",
            " [  4.0102777   -9.1871       7.4591684  ...  -4.826018     2.7697608\n",
            "    4.7740536 ]]\n",
            "Dobijen ocekivan rezultat:  True\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}